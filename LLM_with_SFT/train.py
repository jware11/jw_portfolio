'''
John Ware
Final Project
21 August 2024


This module contains the primary training loop. This is based on the course-provided GPT-2 training 
loop, and modified to apply to Supervised Fine Tuning.

This was run on a Mac M1 chip, so some items are commented out where mac-versions are not available
(i.e. scaler) 

This pulls in a 'dataset.npy' file, as generated by 'construct_sft_dataset.py'

'''

'''
Basic training loop for a GPT model. 

Implements a few additional things not seen in the homeworks:
> autocast, which will use a more efficient datatype for forward pass
> torch.compile, which speeds things up greatly if your hardware supports it

see the flags section to set these.
'''

import torch
import numpy as np
from transformers import AutoModelForCausalLM
import matplotlib.pyplot as plt
import time
import os
import numpy as np
from warmup_cosine import cosine_with_warmup_lr_scheduler
from datasets import load_dataset #used to import HuggingFace file
from batch_mask import batch_mask

# use this to designate a GPU, if you have more than one
# os.environ["CUDA_VISIBLE_DEVICES"] = "3"

# turn on tf32 support, can't hurt [not available on mac]
# torch.backends.mps.matmul.allow_tf32=True #changed cuda to mps
# torch.backends.cudnn.allow_tf32=True

# =============================================================================
# all the settings -------------------------------------

# alternative dtype for forward, set to None to turn off.
# I don't know if this will work out-of-the-box with a HF model.
# AUTOCAST_DTYPE = torch.float16
AUTOCAST_DTYPE = None

# use torch compile? 
# I don't know if this will work out-of-the-box with a HF model.
COMPILE = True #orig set to false

# Model architecture - now defined by gpt2.
ARCHITECTURE = "openai-community/gpt2"

'''
Choices are as follows:
"openai-community/gpt2"
    124M params, 12 layers, 12 heads, d_model=768
"openai-community/gpt2-medium"
    355M params, 24 layers, 16 heads, d_model=1024
"openai-community/gpt2-large"
    774M params, 36 layers, 20 heads, d_model=1280
"openai-community/gpt2-xl"
    1.5B params, 48 layers, 25 heads, d_model=1600
'''

# do we want to use existing gpt2 weights (i.e. for finetuning), or randomize them?
USE_PRETRAINED_WEIGHTS = True # True: USING PRE-TRAINED WEIGHTS

# training hyperparams
# may want to change these for finetuning
PEAK_LR = 0.00005 #orig 0.0005
WARMUP_STEPS = 300
BATCH_SIZE = 4
ACCUMULATION = 4
GRAD_CLIP = 1.0

# =============================================================================

torch.manual_seed(0)

# ------------ model ----------------
device = torch.device("mps") #adjusted from cuda to mps for mac m1
if not torch.backends.mps.is_available(): 
    print('ERROR: cuda not available; gpu not in use')

model = AutoModelForCausalLM.from_pretrained(ARCHITECTURE)
print(model)

param_count = sum(p.numel() for p in model.parameters())
print("PARAMS:", param_count)

model = model.to(device)
model.train()

if not USE_PRETRAINED_WEIGHTS:
    for n, p in model.named_parameters():
        if "bias" in n:
            torch.nn.init.zeros_(p)
        else:
            torch.nn.init.normal_(p, mean=0.0, std=0.01)


# ------------ dataset ----------------

with open('dataset.npy', 'rb') as f: 
    dataset = np.load(f, allow_pickle=True)
print(dataset.shape)

# ------------ some collections ----------------

batch_size = BATCH_SIZE
batches = len(dataset)//batch_size
losses = []
tokens = []
total_tokens = 0

# ------------ loss and opt ----------------

loss_fn = torch.nn.CrossEntropyLoss().to(device) 
opt = torch.optim.AdamW(model.parameters(), lr=PEAK_LR)
scheduler = cosine_with_warmup_lr_scheduler(opt, batches, WARMUP_STEPS)
# scaler = torch.cuda.amp.GradScaler() # LIKELY GOING TO CAUSE ISSUE W/ CUDA VS MPS

# ------------ train loop ----------------

st = time.time() #start time
for b in range(batches*1):
    bdx = b%batches

    x = dataset[batch_size*bdx:batch_size*(bdx+1), :]
    x = torch.from_numpy(x).to(device)    

    # -- MASK INPUT AND TARGET / Mask Batches -- 
    inp, targ = batch_mask(x) 

    if AUTOCAST_DTYPE is not None:
        with torch.autocast(device_type="mps", dtype=AUTOCAST_DTYPE): #changed type from cuda to mps
            y = model(inp)["logits"]
            y = y.transpose(1,2)
            loss = loss_fn(y, targ) # <--- ADD IN IGNORE_INDEX

        scaler.scale(loss).backward()
        if (b+1)%ACCUMULATION==0:
            scaler.unscale_(opt)
            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)
            scaler.step(opt)
            scaler.update()
            opt.zero_grad(set_to_none=True)

    else:
        y = model(inp)["logits"]
        y = y.transpose(1,2)
        loss = loss_fn(y, targ) # <--- ADD IN IGNORE_INDEX
        loss.backward()

        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)

        if (b+1)%ACCUMULATION==0:
            opt.step()
            opt.zero_grad(set_to_none=True)

    scheduler.step()
    b += 1

    # loss tracking ===============================================
    losses.append(loss.item())
    total_tokens += batch_size*256
    tokens.append(total_tokens)
    elapsed = (time.time() - st)/60
    tokens_hr = (total_tokens/elapsed)*60
    print(b, total_tokens, loss.item(), elapsed, "minutes", tokens_hr, "tokens/hr")


    if b>200 and b%100==0:
        plt.clf()

        # get rid of really early data
        plot_tokens = tokens[200:]
        plot_losses = losses[200:] 

        # raw train
        plt.plot(plot_tokens, plot_losses, color='b', alpha=0.2)
        
        # smoothed train
        w = 50
        smoothed = np.convolve(plot_losses, np.ones(w), 'valid') / w
        smoothed_x = plot_tokens[-len(smoothed):]
        plt.plot(smoothed_x, smoothed, color='b')

        # save linear
        plt.xlabel("Training Tokens")
        plt.ylabel("Loss")
        plt.savefig("./loss_plot_v2.png")

        # save weights, huggingface-style
        model.save_pretrained("./my_custom_gpt2_v2")

        # we would load this later with:
        # model = AutoModelForCausalLM.from_pretrained("./my_custom_gpt2")